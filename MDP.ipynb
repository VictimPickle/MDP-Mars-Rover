{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIp1EBp6NbXF"
      },
      "source": [
        "# Mini-Project: The Mars Rover MDP\n",
        "### Course: Artificial Intelligence\n",
        "**Topic:** Markov Decision Processes (MDP) & Dynamic Programming\n",
        "\n",
        "## Project Overview\n",
        "In this project, you will design an autonomous agent for a Mars Rover. The Rover must balance the need to collect scientific data (`Drill`) and transmit it (`Transmit`) against the risk of running out of battery (`Harvest` energy).\n",
        "\n",
        "**The Challenge:** The environment is stochastic. Attempting to charge the battery (Harvest) might fail due to dust storms, and drilling consumes significant energy. Your goal is to implement **Value Iteration** to find the optimal policy $\\pi^*$."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}